version: "3.9"
services:
  ml_app:
    build:
      context: .
    # restart: always
    ports:
      - 8001:8001
    volumes:
      - ./app:/app
    environment:
      - DEBUG=1
    # command: tail -F anything
    command: sh -c "python flame_inferencer.py"
